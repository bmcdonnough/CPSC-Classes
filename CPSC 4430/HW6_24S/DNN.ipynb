{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"d = {\\n    'numpy': '1.21.2',\\n    'pandas': '1.3.2',\\n    \\n    \\n    'sklearn': '1.0',\\n    'torch': '1.8',\\n    'torchvision': '0.9.0'\\n}\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the packages and minimum version requirement are listed below \n",
    "'''d = {\n",
    "    'numpy': '1.21.2',\n",
    "    'pandas': '1.3.2',\n",
    "    \n",
    "    \n",
    "    'sklearn': '1.0',\n",
    "    'torch': '1.8',\n",
    "    'torchvision': '0.9.0'\n",
    "}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision \n",
    "from torchvision import transforms \n",
    "\n",
    "\n",
    "image_path = './'\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "mnist_train_dataset = torchvision.datasets.MNIST(root=image_path, \n",
    "                                           train=True, \n",
    "                                           transform=transform, \n",
    "                                           download=True)\n",
    "mnist_test_dataset = torchvision.datasets.MNIST(root=image_path, \n",
    "                                           train=False, \n",
    "                                           transform=transform, \n",
    "                                           download=False)\n",
    " \n",
    "batch_size = 64\n",
    "torch.manual_seed(1)\n",
    "train_dl = DataLoader(mnist_train_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=32, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (4): ReLU()\n",
       "  (5): Linear(in_features=16, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_units = [32, 16]\n",
    "image_size = mnist_train_dataset[0][0].shape\n",
    "##TODO\n",
    "input_size = \n",
    "\n",
    "all_layers = [nn.Flatten()]\n",
    "#all_layers = []\n",
    "for hidden_unit in hidden_units:\n",
    "    layer = nn.Linear(input_size, hidden_unit)\n",
    "    all_layers.append(layer)\n",
    "    all_layers.append(nn.ReLU())\n",
    "    input_size = hidden_unit\n",
    "##TODO add another Linear layer which maps to 10 classes \n",
    "all_layers.append()\n",
    "model = nn.Sequential(*all_layers)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0  Accuracy 0.8527\n",
      "Epoch 1  Accuracy 0.9338\n",
      "Epoch 2  Accuracy 0.9460\n",
      "Epoch 3  Accuracy 0.9540\n",
      "Epoch 4  Accuracy 0.9589\n",
      "Epoch 5  Accuracy 0.9620\n",
      "Epoch 6  Accuracy 0.9667\n",
      "Epoch 7  Accuracy 0.9686\n",
      "Epoch 8  Accuracy 0.9704\n",
      "Epoch 9  Accuracy 0.9727\n",
      "Epoch 10  Accuracy 0.9748\n",
      "Epoch 11  Accuracy 0.9760\n",
      "Epoch 12  Accuracy 0.9773\n",
      "Epoch 13  Accuracy 0.9786\n",
      "Epoch 14  Accuracy 0.9796\n",
      "Epoch 15  Accuracy 0.9806\n",
      "Epoch 16  Accuracy 0.9819\n",
      "Epoch 17  Accuracy 0.9823\n",
      "Epoch 18  Accuracy 0.9836\n",
      "Epoch 19  Accuracy 0.9839\n"
     ]
    }
   ],
   "source": [
    "## TODO define the loss function for multiclassification task \n",
    "loss_fn = \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "torch.manual_seed(1)\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    accuracy_hist_train = 0\n",
    "    for x_batch, y_batch in train_dl:\n",
    "       \n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        #TODO finish the 5 steps (lines) training for Deep Learning\n",
    "        is_correct = (torch.argmax(pred, dim=1) == y_batch).float()\n",
    "        accuracy_hist_train += is_correct.sum()\n",
    "    accuracy_hist_train /= len(train_dl.dataset)\n",
    "    print(f'Epoch {epoch}  Accuracy {accuracy_hist_train:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9700\n"
     ]
    }
   ],
   "source": [
    "model=model.to('cpu')\n",
    "#TODO: check the test accuracy\n",
    "print(f'Test accuracy: {is_correct.mean():.4f}') \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
